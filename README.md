# Paraphrase Detection System ğŸš€

[![Production Ready](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)](PROJECT_STATUS.md)
[![Docker](https://img.shields.io/badge/Docker-Enabled-blue)](Dockerfile)
[![Architecture](https://img.shields.io/badge/Architecture-Siamese%20Network-orange)](docs/ARCHITECTURE_IMPLEMENTATION.md)
[![API](https://img.shields.io/badge/API-FastAPI-green)](backend/api.py)
[![Deploy](https://img.shields.io/badge/Deploy-Railway%20%7C%20Render-purple)](DEPLOYMENT.md)

## Overview
Production-ready document-level paraphrase detection using SBERT embeddings, Siamese neural networks, and multi-agent AI evaluation. Deployable to Railway, Render, Vercel, or any Docker-compatible platform.

**âœ… 100% Complete:** Full implementation with REST API, Docker support, and comprehensive documentation. See [PROJECT_STATUS.md](PROJECT_STATUS.md) for details.

## âš¡ Quick Start

### Option 1: Docker (Recommended)
```bash
# 1. Clone and setup
git clone <your-repo>
cd paraphrase-detection
cp .env.template .env
# Add your GROQ_API_KEY to .env

# 2. Run with Docker
docker-compose up --build

# 3. Test API
curl http://localhost:8000/health
```

### Option 2: Deploy to Railway (5 minutes)
```bash
# 1. Push to GitHub
git push origin main

# 2. Go to railway.app
# 3. Click "Deploy from GitHub"
# 4. Add GROQ_API_KEY in environment variables
# 5. Done! Auto-deploys with Dockerfile
```

See [QUICKSTART.md](QUICKSTART.md) for more deployment options.

---

## ğŸ—ï¸ Architecture

### Document-Level Pipeline
```
Documents â†’ Chunking â†’ SBERT (frozen) â†’ Aggregation â†’ Neural Network â†’ Feature Vectors â†’ Cosine Similarity â†’ Threshold â†’ Result
                                â†“
                      all-MiniLM-L6-v2 (384-dim)
                                â†“
                    Shared-weight Projection Head
                           (256-dim output)
```

### Multi-Agent Evaluation (Optional)
```
Test Cases â†’ ParaphraseGenerator â†’ AdversarialGenerator â†’ EvaluationOrchestrator â†’ Performance Report
```

**Architecture Details**: See [docs/ARCHITECTURE_IMPLEMENTATION.md](docs/ARCHITECTURE_IMPLEMENTATION.md)

---

## ğŸ“ Project Structure

```
paraphrase-detection/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py                          # FastAPI REST server âœ…
â”‚   â”œâ”€â”€ config.py                       # Configuration management âœ…
â”‚   â”œâ”€â”€ document_siamese_pipeline.py    # Complete ML pipeline âœ…
â”‚   â”œâ”€â”€ neural_engine.py                # SBERT + Neural Network âœ…
â”‚   â”œâ”€â”€ agentic_evaluator.py            # Multi-agent system âœ…
â”‚   â””â”€â”€ setup_production.py             # Production setup script âœ…
â”œâ”€â”€ docs/                                # Comprehensive documentation
â”œâ”€â”€ .env.template                        # Environment template âœ…
â”œâ”€â”€ Dockerfile                           # Multi-stage production image âœ…
â”œâ”€â”€ docker-compose.yml                   # Service orchestration âœ…
â”œâ”€â”€ railway.json                         # Railway deployment âœ…
â”œâ”€â”€ render.yaml                          # Render deployment âœ…
â”œâ”€â”€ requirements.txt                     # Python dependencies âœ…
â””â”€â”€ DEPLOYMENT.md                        # Deployment guides âœ…
```

---

## ğŸŒ API Endpoints

```bash
GET  /                    # API information
GET  /health              # Health check + model status
POST /api/compare         # Compare two documents
POST /api/compare/batch   # Batch comparison
POST /api/compare/files   # File upload comparison
GET  /api/model/info      # Model configuration
```

### Example Usage
```bash
curl -X POST http://localhost:8000/api/compare \
  -H "Content-Type: application/json" \
  -d '{
    "text1": "Machine learning is transforming industries.",
    "text2": "ML is revolutionizing various sectors."
  }'
```

**Response:**
```json
{
  "similarity": 0.87,
  "is_paraphrase": true,
  "confidence": "high",
  "processing_time": 0.45
}
```

---

## ğŸ”§ Configuration

### Required Environment Variables
```bash
# Get free API key at: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here
```

### Optional Configuration
```bash
ENVIRONMENT=production
API_PORT=8000
LOG_LEVEL=info
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
SIMILARITY_THRESHOLD=0.75
```

See [.env.template](.env.template) for all configuration options.

---

## ğŸ“š Documentation

### Getting Started
- [QUICKSTART.md](QUICKSTART.md) - Deploy in 5 minutes
- [DEPLOYMENT.md](DEPLOYMENT.md) - Platform-specific deployment guides
- [PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md) - Production best practices

### Technical Details
- [PROJECT_STATUS.md](PROJECT_STATUS.md) - Complete implementation status
- [docs/ARCHITECTURE_IMPLEMENTATION.md](docs/ARCHITECTURE_IMPLEMENTATION.md) - Full architecture guide
- [docs/QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md) - Common commands
- [docs/AUDIT_REPORT.md](docs/AUDIT_REPORT.md) - Senior ML engineer audit

### Training & Development
- [docs/TRAINING_ARCHITECTURE.md](docs/TRAINING_ARCHITECTURE.md) - Training details
- [docs/HOW_IT_WORKS.md](docs/HOW_IT_WORKS.md) - System explanation

---

## ğŸš€ Deployment Options

| Platform | Setup Time | Cost | Best For |
|----------|------------|------|----------|
| **Railway** | 5 min | $5/mo | Production (Recommended) |
| **Render** | 10 min | $7/mo | Production |
| **Docker** | 2 min | Free | Local development |
| **Vercel** | 5 min | $20/mo | Lightweight APIs |

**Detailed guides**: See [DEPLOYMENT.md](DEPLOYMENT.md)

---

## ğŸ§ª Testing

### Local Testing
```bash
# Install dependencies
pip install -r requirements.txt

# Run setup script
python backend/setup_production.py

# Start server
python -m uvicorn backend.api:app --reload

# Test
curl http://localhost:8000/health
```

### Docker Testing
```bash
# Build and run
docker-compose up --build

# Test health
curl http://localhost:8000/health

# Test comparison
curl -X POST http://localhost:8000/api/compare \
  -H "Content-Type: application/json" \
  -d '{"text1": "Hello world", "text2": "Hi there"}'
```

---

## ğŸ“Š Performance

### Expected Metrics (Medium Hardware)
- **Single Comparison**: ~0.3-0.5 seconds
- **Batch Processing** (10 docs): ~2-3 seconds
- **Model Loading**: ~5-10 seconds (one-time)
- **Memory Usage**: ~500MB-1GB (SBERT loaded)
- **API Response**: <1 second

### Optimization
- âœ… SBERT weights frozen (no gradient computation)
- âœ… Batch processing for efficiency
- âœ… Configurable chunk sizes
- ğŸ’¡ Add Redis caching for 10x performance boost

---

## ğŸ› ï¸ Development

### Local Development
```bash
# Hot reload mode
docker-compose --profile dev up

# Or without Docker
python -m uvicorn backend.api:app --reload --host 0.0.0.0 --port 8000
```

### Adding Features
1. Update code in `backend/`
2. Test locally with `docker-compose up`
3. Update documentation
4. Push to GitHub (auto-deploys on Railway)

---

## ğŸ”’ Security

- âœ… Environment variable management (no secrets in code)
- âœ… `.gitignore` excludes sensitive files
- âœ… Non-root Docker user
- âœ… CORS configuration
- âœ… Input validation with Pydantic
- ğŸ’¡ Add JWT authentication for production use

---

## ğŸ¤ Contributing

This project is fully documented and ready for contributions:

1. Review [docs/ARCHITECTURE_IMPLEMENTATION.md](docs/ARCHITECTURE_IMPLEMENTATION.md)
2. Check [PROJECT_STATUS.md](PROJECT_STATUS.md) for current status
3. Make changes and test locally
4. Submit pull request

---

## ğŸ“ License

See [LICENSE](LICENSE) file for details.

---

## ğŸ†˜ Troubleshooting

### Common Issues

**Port already in use:**
```bash
# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

**Model download fails:**
```bash
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
```

**Docker issues:**
```bash
docker system prune -a
docker-compose up --build
```

**More help**: See [PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md) troubleshooting section

---

## ğŸ“ Support

- **Documentation**: Comprehensive guides in `docs/` folder
- **Quick Start**: [QUICKSTART.md](QUICKSTART.md)
- **Deployment**: [DEPLOYMENT.md](DEPLOYMENT.md)
- **Status**: [PROJECT_STATUS.md](PROJECT_STATUS.md)

---

## âœ¨ What's Included

âœ… **Complete ML Pipeline**: SBERT + Siamese Network + Document Processing  
âœ… **REST API**: FastAPI with 6 endpoints  
âœ… **Multi-Agent AI**: CrewAI-based evaluation system  
âœ… **Docker Support**: Multi-stage production image  
âœ… **Multiple Platforms**: Railway, Render, Vercel, Heroku  
âœ… **Configuration**: 50+ environment variables  
âœ… **Documentation**: 10+ comprehensive guides  
âœ… **Security**: Best practices for production  

**Status**: ğŸŸ¢ **100% Production Ready**

---

## ğŸ¯ Next Steps

1. **Quick Test**: `docker-compose up --build`
2. **Deploy**: Follow [QUICKSTART.md](QUICKSTART.md)
3. **Monitor**: Check logs and performance
4. **Scale**: Add Redis caching, authentication, monitoring

**Recommended Platform**: Railway (easiest, affordable, reliable)

---

**Built with â¤ï¸ using PyTorch, FastAPI, and Sentence Transformers**
